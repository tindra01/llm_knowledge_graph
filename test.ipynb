{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab99fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcab217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05045bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8182ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SystemPrompt = \"\"\"You are a helpful assistant for extracting human language knowledge into\n",
    "triple structures.\n",
    "\n",
    "## Task\n",
    "- Extract ALL possible knowledge triples from the given Korean text.\n",
    "- A triple consists of (subject, predicate, object).\n",
    "- The subject is the entity being described.\n",
    "- The predicate describes the action, state, or nature of the subject.\n",
    "- The object is the target of that predicate.\n",
    "- Extract explicit and implicit knowledge.\n",
    "- Entities may represent people, objects, concepts, events, roles, etc.\n",
    "\n",
    "## Output Requirements\n",
    "1. Every triple MUST be formatted exactly like this:\n",
    "(주어, 서술어, 목적어)\n",
    "2. Each triple MUST be separated by the delimiter:\n",
    "<|>\n",
    "3. The entire answer MUST be a single string without a list, without quotes.\n",
    "4. The answer MUST be in Korean.\n",
    "5. Include as many knowledge triples as possible.\n",
    "6. Natural language expressions are allowed in predicate and object.\n",
    "\n",
    "## Example 1\n",
    "Input:\n",
    "\"생성 모델은 데이터를 학습하고 새로운 샘플을 생성한다.\"\n",
    "\n",
    "Output:\n",
    "(생성 모델, 데이터, 학습)<|>(생성 모델, 새로운 샘플, 생성)\n",
    "\n",
    "## Example 2\n",
    "Input:\n",
    "\"머신러닝 기법 중 선형 회귀(Linear Regression)는 대표적인 회귀 문제에 속하고, 로지스틱 회귀\n",
    "(Logistic Regression)은 대표적인 분류 문제에 속한다.\n",
    "분류는 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification) 등으로 나\n",
    "뉜다.\"\n",
    "\n",
    "Output:\n",
    "(머신러닝, 기법, 선형 회귀)<|>(선형 회귀, 회귀 문제, 속함)<|>(머신러닝, 기법, 로지스틱 회\n",
    "귀)<|>(로지스틱 회귀, 분류 문제, 속함)<|>(분류, 이진 분류, 나뉨)<|>(분류, 다중 클래스 분류, 나\n",
    "뉨)\n",
    "\n",
    "Now extract knowledge triples from the following context:\n",
    "\n",
    "{context} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0a0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(llm_output):\n",
    "    #LLM output parsing\n",
    "    if not llm_output:\n",
    "        return []\n",
    "    return llm_output.split(\"<|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476633cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphcategory(parsing_output):\n",
    "    #parsing 된 것을 graph category 화\n",
    "    triples_list = [i.replace(\"(\",\"\").replace(\")\",\"\") for i in parsing_output]\n",
    "    data = [j.split(\",\") for j in triples_list]\n",
    "    categorized_data = [[item[0].strip(), item[2].strip(), item[1].strip()] for item in data]\n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed9b99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_knowledge_graph(context):\n",
    "    PROMPT = PromptTemplate.from_template(SystemPrompt)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model = 'gemini-2.5-flash',\n",
    "        temperature=0.1\n",
    "    )\n",
    "    chain = PROMPT | llm\n",
    "    qa = chain.invoke(context)\n",
    "    #llm 결과\n",
    "    llm_output = qa.content\n",
    "    #llm 결과 parsing\n",
    "    parsing_output = parse_output(llm_output)\n",
    "    #parsing 데이터 graphcategory화\n",
    "    categorized_data = graphcategory(parsing_output)\n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ceb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-knowledge-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
